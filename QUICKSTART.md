# HR Employee Lifecycle Demo - Quick Start

## üì¶ What's Included

This complete Microsoft Fabric demo package contains:

### ‚úÖ Data Generation
- **Python script**: `src/generate_hr_data.py`
  - Generates 500 synthetic employees
  - 8 CSV files (employees, departments, positions, events, compensation, absences, training, cases)
  - 200+ text reports (performance reviews, exit interviews, case notes)
  - 100% fictional data (RGPD-safe)

### ‚úÖ Configuration
- `config.yaml` - Customize volumes, distributions, date ranges
- `requirements.txt` - Python dependencies
- `AGENTS.md` - Copilot/agent development guidelines

### ‚úÖ Notebooks (Fabric)
- `notebooks/00_generate_synthetic_hr_data.ipynb` - Data generation (run first)
- `notebooks/01_silver_modeling.ipynb` - Bronze ‚Üí Silver transformation
- `notebooks/02_text_enrichment.ipynb` - AI PII redaction + summarization
- `notebooks/03_semantic_and_agent_assets.md` - Complete setup guide

### ‚úÖ Agent Configuration
- `agent/agent_instructions.md` - Comprehensive system prompt (copy to Data Agent)
- `agent/example_queries.json` - 70+ example questions organized by category

### ‚úÖ Documentation
- `README.md` - Overview & 10-minute demo script
- `docs/schema.md` - Complete data dictionary (18 tables)
- `docs/demo_story.md` - Narrative demo walkthrough ("From Hire to Champion")
- `docs/data_dictionary.md` - Auto-generated by data generator

---

## üöÄ Quick Start (30 Minutes)

### Step 1: Generate Data (5 min)
```powershell
cd src
python generate_hr_data.py
```
**Output**: `data/raw/hr/*.csv` + `data/raw/reports_txt/*.txt`

### Step 2: Create Fabric Workspace & Lakehouse (5 min)
1. Go to Microsoft Fabric
2. Create Workspace: `HR_Analytics_Demo`
3. Create Lakehouse: `hr_lakehouse`

### Step 3: Upload Data (5 min)
Upload all CSV and TXT files to Lakehouse Files:
- `hr_raw/` folder ‚Üí 8 CSV files
- `reports_txt/` folder ‚Üí 200 TXT files

### Step 4: Apply Shortcut Transformations (5 min)
For each CSV file, create:
- OneLake Shortcut
- Shortcut Transformation (Auto-sync to Delta)
- Target: `bronze_*` tables

### Step 5: Run Notebooks (5 min)
1. Upload `01_silver_modeling.ipynb` ‚Üí Run all
2. Upload `02_text_enrichment.ipynb` ‚Üí Run all

### Step 6: Create Data Agent (5 min)
1. New ‚Üí Data Agent
2. Name: `HR_Lifecycle_Agent`
3. Source: `hr_lakehouse` (Direct Lake)
4. Instructions: Paste `agent/agent_instructions.md`
5. Examples: Import `agent/example_queries.json`

### Step 7: Test! (Demo time)
Ask the agent:
- "What is our current headcount?"
- "What's our attrition rate this year?"
- "What are the main themes from exit interviews?"

---

## üéØ Key Demo Messages

1. **OneLake = No Silos**
   - All HR data in one place
   - Zero-copy shortcuts

2. **Shortcut Transformations = No ETL**
   - CSV ‚Üí Delta in 2 clicks
   - Auto-refresh

3. **AI = Unlock Text Data**
   - 200 reports analyzed in 10 minutes
   - PII auto-redacted (GDPR-compliant)

4. **Data Agent = No SQL**
   - Conversational analytics
   - Self-serve for all stakeholders

5. **Fabric = One Platform**
   - Lakehouse + AI + Agent together
   - No tool stitching

---

## üìä Dataset Overview

- **Employees**: 500 (445 active, 55 terminated)
- **Departments**: 12
- **Positions**: 45
- **Lifecycle Events**: ~4,000 (hires, promotions, exits, reviews)
- **Compensation Records**: ~1,500
- **Absences**: ~3,000
- **Training Records**: ~2,500
- **HR Cases**: ~150
- **Text Reports**: ~200 (AI-enriched)

**Date Range**: 2023-01-01 to 2025-12-31 (3 years)

---

## üîß Customization

### Change Volumes
Edit `config.yaml`:
```yaml
volumes:
  employees: 1000  # Double the employees
  lifecycle_events_per_employee_avg: 10  # More events
```
Re-run: `python src/generate_hr_data.py`

### Add New Event Type
Edit `config.yaml`:
```yaml
lifecycle_events:
  - event_type: "sabbatical_leave"
    weight: 2
    avg_per_employee: 0.05
```

### Modify AI Prompts
Edit `agent/agent_instructions.md` to customize:
- Response tone
- Privacy guardrails
- Metric definitions
- Example patterns

---

## üõ†Ô∏è Troubleshooting

| Issue | Solution |
|-------|----------|
| Data generation fails | Check Python version (‚â•3.8), install requirements.txt |
| Shortcut transformation not syncing | Verify CSV format, check transformation logs |
| AI functions not available | Use regex fallback in notebook 02 (included) |
| Data Agent exposes PII | Re-paste agent_instructions.md, verify guardrails section |
| Agent can't answer questions | Check data source connection, verify table relationships |

---

## üìö Resources

- **Fabric Docs**: https://learn.microsoft.com/en-us/fabric/
- **Data Agent Guide**: https://learn.microsoft.com/en-us/fabric/data-science/data-agent
- **OneLake Shortcuts**: https://learn.microsoft.com/en-us/fabric/onelake/onelake-shortcuts
- **AI Functions**: https://learn.microsoft.com/en-us/fabric/data-science/ai-services

---

## ‚úÖ Success Checklist

- [x] Data generated (8 CSV + 200 TXT files)
- [x] Lakehouse created in Fabric
- [x] Data uploaded to OneLake
- [x] Bronze tables created via Shortcut Transformations
- [x] Silver/Gold tables created via notebooks
- [x] AI enrichment applied to text reports
- [x] Data Agent configured with instructions
- [x] Tested 10 "wow" questions successfully
- [x] Demo story reviewed
- [x] Ready to present!

---

**Total Setup Time**: ~30 minutes
**Demo Time**: 10-15 minutes
**Impact**: Transform HR analytics from days ‚Üí seconds

**üéâ You're ready to demo HR Employee Lifecycle Analytics with Microsoft Fabric!**
