# HR Employee Lifecycle Analytics - Microsoft Fabric Demo

## üéØ Vue d'Ensemble

Cette d√©mo illustre une solution compl√®te d'analytique RH sur **Microsoft Fabric** avec :
- ‚úÖ **OneLake + Shortcuts** : Ingestion de donn√©es RH brutes
- ‚úÖ **Shortcut Transformations** : Mat√©rialisation automatique en Delta tables (Bronze ‚Üí Silver)
- ‚úÖ **AI Transformations** : Redaction PII + Summarization des rapports RH
- ‚úÖ **Star Schema** : Mod√®le dimensionnel pour analytics
- ‚úÖ **Fabric Data Agent** : Conversations en langage naturel sur les donn√©es RH

---

## üìä Cas d'Usage

Analyser le cycle de vie complet des employ√©s :
- Recrutement et onboarding
- Mobilit√© interne et promotions
- Performance et formation
- Absences et cong√©s
- D√©parts (d√©missions / licenciements)
- Cas RH (disciplinaires, conflits, r√©clamations)

**~500 employ√©s** | **3 ans d'historique** | **200+ rapports RH textuels**

---

## üìÅ Structure du Repo

```
Scenario 10 - HR/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 00_generate_synthetic_hr_data.ipynb   # G√©n√©ration donn√©es synth√©tiques
‚îÇ   ‚îú‚îÄ‚îÄ 01_silver_modeling.ipynb              # Transformation Bronze ‚Üí Silver
‚îÇ   ‚îú‚îÄ‚îÄ 02_text_enrichment.ipynb              # AI PII redaction + summarization
‚îÇ   ‚îî‚îÄ‚îÄ 03_semantic_and_agent_assets.md       # Setup Fabric Data Agent
‚îú‚îÄ‚îÄ agent/
‚îÇ   ‚îú‚îÄ‚îÄ agent_instructions.md                  # System prompt Data Agent
‚îÇ   ‚îî‚îÄ‚îÄ example_queries.json                   # 25+ exemples de questions
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ raw/                                   # Donn√©es brutes g√©n√©r√©es
‚îÇ       ‚îú‚îÄ‚îÄ hr/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ employees.csv
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ departments.csv
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ positions.csv
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ lifecycle_events.csv
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ compensation_history.csv
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ absences.csv
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ training_records.csv
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ hr_cases.csv
‚îÇ       ‚îî‚îÄ‚îÄ reports_txt/                       # ~200 rapports .txt
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ schema.md                              # Dictionnaire de donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ demo_story.md                          # Sc√©nario narratif
‚îÇ   ‚îî‚îÄ‚îÄ data_dictionary.md                     # Documentation g√©n√©r√©e
‚îú‚îÄ‚îÄ config.yaml
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ AGENTS.md
‚îî‚îÄ‚îÄ README.md (ce fichier)
```

---

## üöÄ D√©marrage Rapide

### 1Ô∏è‚É£ G√©n√©rer les Donn√©es Synth√©tiques

```python
# Ouvrir le notebook notebooks/00_generate_synthetic_hr_data.ipynb
# Ex√©cuter toutes les cellules (Ctrl+Shift+Enter)
```

**Output** :
- `data/raw/hr/*.csv` : 8 tables CSV
- `data/raw/reports_txt/*.txt` : ~200 rapports textuels
- `docs/data_dictionary.md` : Sch√©ma relationnel complet

**Dur√©e** : ~2-3 minutes

---

### 2Ô∏è‚É£ Cr√©er le Lakehouse dans Fabric

1. Ouvrir **Microsoft Fabric** (app.fabric.microsoft.com)
2. Cr√©er un **Workspace** : `HR_Analytics_Demo`
3. Cr√©er un **Lakehouse** : `hr_lakehouse`

---

### 3Ô∏è‚É£ Uploader les Fichiers Bruts

**Option A : Via UI**
1. Ouvrir `hr_lakehouse` ‚Üí **Files**
2. Cr√©er dossier `hr_raw`
3. Uploader tous les CSV de `data/raw/hr/`
4. Cr√©er dossier `reports_txt`
5. Uploader tous les .txt de `data/raw/reports_txt/`

**Option B : Via Notebook**
```python
# Dans un notebook Fabric
import os
for csv_file in ["employees.csv", "departments.csv", ...]:
    df = pd.read_csv(f"path/to/local/{csv_file}")
    df.write.format("delta").mode("overwrite").save(f"Files/hr_raw/{csv_file}")
```

---

### 4Ô∏è‚É£ Configurer les Shortcut Transformations

1. **Bronze Layer** : Cr√©er shortcuts vers `hr_raw/`
   - Clic droit sur dossier `hr_raw` ‚Üí **New shortcut**
   - S√©lectionner **OneLake**
   - Pointer vers `Files/hr_raw/`

2. **Shortcut Transformation (CSV ‚Üí Delta)**
   - Clic droit sur shortcut ‚Üí **New shortcut transformation**
   - Type : **Auto-sync to Delta**
   - Output : `Tables/bronze_employees` (r√©p√©ter pour chaque CSV)

3. **Attendre la synchronisation** (1-2 min)

---

### 5Ô∏è‚É£ Ex√©cuter les Notebooks de Transformation

#### **Notebook 01 : Silver Modeling**

```python
# notebooks/01_silver_modeling.ipynb
# - Lit les tables bronze_*
# - Nettoyage (dates, enums, nulls)
# - Cr√©e dim_employee, dim_department, dim_position, dim_date
# - Cr√©e fact_lifecycle_event, fact_compensation, fact_absence, fact_training, fact_hr_case
```

**Output** : Tables Silver dans `Tables/silver_*` et dimensions/facts dans `Tables/gold_*`

---

#### **Notebook 02 : Text Enrichment (AI)**

```python
# notebooks/02_text_enrichment.ipynb
# - Lit reports_txt/*.txt
# - PII Detection + Redaction (emails, t√©l√©phones, noms)
# - Summarization avec Fabric AI Functions
# - Topic Extraction
# - Output : fact_hr_report Delta table
```

**Output** : `Tables/gold_fact_hr_report`

---

### 6Ô∏è‚É£ Cr√©er le Data Agent

1. **Cr√©er un Semantic Model (optionnel)**
   - Power BI Desktop : Importer tables Gold
   - D√©finir relations (employee_key, date_key)
   - Cr√©er mesures DAX (cf. `docs/dax_measures.md`)
   - Publier dans Fabric Workspace

2. **Cr√©er le Data Agent**
   - Workspace ‚Üí **+ New** ‚Üí **Data Agent**
   - Nom : `HR_Lifecycle_Agent`
   - Source : S√©lectionner Semantic Model OU Direct Lake (Lakehouse)
   - **System Instructions** : Copier/coller `agent/agent_instructions.md`
   - **Example Queries** : Importer `agent/example_queries.json`

3. **Tester le Data Agent**
   - Poser des questions (cf. section "10 Questions WOW")

---

## üí¨ 10 Questions "WOW" pour le Data Agent

### 1. **Headcount & Attrition**
> "Quel est notre headcount actuel et comment a-t-il √©volu√© sur les 3 derni√®res ann√©es ?"

### 2. **Taux d'Attrition**
> "Quel est notre taux d'attrition annuel ? Quel d√©partement a le plus fort turnover ?"

### 3. **Promotions**
> "Combien d'employ√©s ont √©t√© promus en 2025 ? Quel est le temps moyen avant promotion ?"

### 4. **Mobilit√© Interne**
> "Montre-moi les transferts inter-d√©partements des 6 derniers mois."

### 5. **Performance Reviews**
> "R√©sume les th√®mes principaux des performance reviews de Q4 2025."  
> *(AI summarization des rapports textuels)*

### 6. **Formation**
> "Quel type de formation est le plus suivi par les ing√©nieurs ?"

### 7. **Absences**
> "Quelle est la moyenne de jours d'absence par employ√© par an ?"

### 8. **Cas RH**
> "Combien de cas RH ouverts actuellement ? Quel est le type le plus fr√©quent ?"

### 9. **Exit Interviews**
> "Quelles sont les raisons principales de d√©part mentionn√©es dans les exit interviews ?"  
> *(AI topic extraction sur les rapports de sortie)*

### 10. **KPIs Ex√©cutifs**
> "Affiche le dashboard des 5 KPIs RH cl√©s : headcount, attrition, temps de recrutement, formation, satisfaction."

---

## üìñ Sc√©nario de D√©mo (10-15 minutes)

### **Slide 1 : Contexte (1 min)**
> "Vous √™tes DRH d'une scale-up tech de 500 employ√©s. Vous devez piloter le cycle de vie complet : recrutement, mobilit√©, performance, d√©parts."

### **Slide 2 : Donn√©es Brutes dans OneLake (2 min)**
- Montrer `Files/hr_raw/` : 8 CSV + rapports .txt
- Souligner : **Aucune donn√©e r√©elle** (tout synth√©tique, RGPD-safe)
- Montrer un fichier .txt : contient PII fictives (emails, t√©l√©phones)

### **Slide 3 : Shortcut Transformations (2 min)**
- Montrer shortcuts OneLake
- Montrer **Auto-sync to Delta** : CSV ‚Üí Bronze tables
- B√©n√©fice : **Z√©ro ETL**, synchronisation automatique

### **Slide 4 : AI Redaction + Summarization (3 min)**
- Montrer `fact_hr_report` avec colonnes :
  - `report_text_redacted` : PII remplac√©es par `[EMAIL]`, `[PHONE]`, etc.
  - `report_summary` : R√©sum√© 2-3 phrases g√©n√©r√© par AI
  - `topics` : Th√®mes extraits (performance, conflict, resignation_reason)
- B√©n√©fice : **Conformit√© RGPD** + **Insights en langage naturel**

### **Slide 5 : Star Schema & Semantic Model (2 min)**
- Montrer architecture :
  - **Dimensions** : dim_employee (SCD Type 2), dim_department, dim_position, dim_date
  - **Facts** : fact_lifecycle_event, fact_compensation, fact_absence, fact_training, fact_hr_case, fact_hr_report
- Relations : employee_key, date_key
- M√©triques DAX pr√©-calcul√©es

### **Slide 6 : Data Agent en Action (5 min)**
- Poser les 10 questions WOW (ci-dessus)
- Montrer :
  - R√©ponses en fran√ßais
  - Visualisations automatiques (tableaux, graphiques)
  - Drill-down : cliquer sur un d√©partement ‚Üí d√©tails
  - Explications : "Comment as-tu calcul√© ce KPI ?"

### **Slide 7 : Conclusion (1 min)**
> "Avec Fabric : OneLake + AI + Data Agent, vous passez de **silos RH** √† une **vue 360¬∞ pilotable en conversation**."

---

## üßÆ M√©triques RH Calcul√©es

### **Headcount**
```
Headcount Actuel = COUNT(employees WHERE status = 'active')
```

### **Attrition Rate**
```
Attrition Annuel = (Exits / AVG(Headcount)) √ó 100%
```

### **Time to Fill**
```
Time to Fill = Hire Date - Requisition Date (moy. 45-60 jours)
```

### **Promotion Rate**
```
Promotion Rate = (Promotions / Headcount) √ó 100%
```

### **Training Hours per FTE**
```
Training Hours per FTE = SUM(training_hours) / Headcount
```

### **Internal Mobility Rate**
```
Internal Mobility = (Transfers + Promotions) / Headcount
```

### **Case Resolution Time**
```
Avg Case Resolution Time = AVG(resolution_date - case_date)
```

---

## üîê Conformit√© RGPD / Donn√©es Synth√©tiques

**‚ö†Ô∏è ATTENTION** : Ce repo contient **UNIQUEMENT des donn√©es fictives**.

- **Noms** : G√©n√©r√©s par Faker (noms europ√©ens al√©atoires)
- **Emails** : Format `prenom.nom@example.com` (domaine fictif)
- **T√©l√©phones** : Format europ√©en fictif (ex: +33 6 XX XX XX XX)
- **Aucune vraie donn√©e personnelle**

**D√©mo PII Redaction** :
- Les rapports textuels incluent des PII fictives
- Le notebook 02 d√©tecte et redacte ces PII
- Seule la version redact√©e est expos√©e dans le Data Agent

**En production r√©elle** :
- Appliquer RBAC (Row-Level Security) par manager_id
- Anonymiser/pseudonymiser selon RGPD
- Audit trail des acc√®s
- Retention policies

---

## üìö Documentation Compl√©mentaire

- [`docs/schema.md`](docs/schema.md) : Sch√©ma complet des 16 tables
- [`docs/demo_story.md`](docs/demo_story.md) : Sc√©nario narratif "Du Recrutement au D√©part"
- [`agent/agent_instructions.md`](agent/agent_instructions.md) : System prompt Data Agent
- [`agent/example_queries.json`](agent/example_queries.json) : 25 questions exemple
- [`notebooks/03_semantic_and_agent_assets.md`](notebooks/03_semantic_and_agent_assets.md) : Setup d√©taill√© Fabric

---

## üõ†Ô∏è Customisation

### Modifier les Volumes
√âditer `config.yaml` :
```yaml
volumes:
  employees: 1000  # Au lieu de 500
  lifecycle_events_per_employee_avg: 10  # Au lieu de 8
```
Relancer `00_generate_synthetic_hr_data.ipynb`

### Ajouter un Type d'√âv√©nement
√âditer `config.yaml` :
```yaml
lifecycle_events:
  - event_type: "sabbatical_leave"
    weight: 2
    avg_per_employee: 0.05
```

### Ajouter un Rapport Texte
√âditer le notebook 00, section "Generate HR Reports" :
```python
report_templates['sabbatical_request'] = {
    'opening': "Employee {employee_id} has requested a sabbatical...",
    ...
}
```

---

## üèÜ B√©n√©fices de la Solution

| Avant | Apr√®s (avec Fabric) |
|-------|---------------------|
| Donn√©es RH √©parpill√©es (Excel, SIRH, emails) | **OneLake centralis√©** |
| Rapports manuels (copier/coller) | **Auto-refresh Delta** |
| Aucune analyse des comptes rendus RH | **AI summarization + topic extraction** |
| Requ√™tes SQL complexes | **Conversations Data Agent** |
| PII expos√©es dans rapports | **Redaction automatique** |
| D√©lai 2-3 jours pour un KPI | **R√©ponse instantan√©e** |

---

## üìû Support

Questions sur :
- **Code** : Voir `AGENTS.md` (conventions Copilot)
- **Fabric** : [Documentation officielle](https://learn.microsoft.com/en-us/fabric/)
- **Data Agent** : `agent/agent_instructions.md`

---

**Pr√™t √† d√©ployer ? Commencez par `notebooks/00_generate_synthetic_hr_data.ipynb` ! üöÄ**
